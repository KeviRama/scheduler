Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2016-11-10T09:50:45+00:00

====== Thursday 10 Nov 2016 ======

My batch jobs from yesterday seem to work, but I think I've got my plan for the timings all wrong.  Currently I have:

'''
#
#  Checking for clashes is a long job - run it in the evening most
#  of the time, but also on Sunday mornings to get the new week's
#  information in.  Thus no point in running it on Saturday eve.
#  Or indeed on Fri eve, since there's no week left to check.
#
0 20 * * 1-4 /home/john/Work/Coding/scheduler/utils/checkclashes
0 7 * * 0 /home/john/Work/Coding/scheduler/utils/checkclashes
#42 12 * * * /home/john/Work/Coding/scheduler/utils/checkclashes
#
#  Weekly notifications are done on Sunday evening.  Note that this
#  will also notify anyone who has requested daily notification.
#
0 20 * * 0 /home/john/Work/Coding/scheduler/utils/weeklyclashsummary
#
#  And then daily notifications on Tue-Fri morning.  There's no
#  point in sending one on Monday morning because there will be
#  no fresh information since Sunday evening.
#
0 7 * * 2-5 /home/john/Work/Coding/scheduler/utils/dailyclashsummary
'''


on my staging server, the idea being to do it in the evening before the backup etc.  However this is the wrong time.  The update from iSAMS happens every morning at 4 a.m. and it would make sense to have the run after that so it can use the latest data, even if that means moving the iSAMS update.

I regard 01:00 to 02:00 as a bit of a no-go area because of the risk of complications when DST begins and ends.  That means I want to do things either before then or after then.  When are all the existing batch jobs on the live system?

Diversion - there seems to be a problem with people creating new accounts on the live scheduler system.  Investigate.

As a side issue, I'm getting a lot of requests for:

apple-touch-icon.png
apple-touch-icon-precomposed.png
apple-touch-icon-152x152.png

which result in long error messages.  Have added empty files of that name to public as a temporary measure.  Presumably one should do something a bit more serious.  Apple are getting like Microsoft in their we-do-what-we-like attitude.

Well, got a little way with Niki's problem.  The actual error seems to be being generated by Google and not by Scheduler.  Not a lot I can do about that.

However - I have just noticed a genuine error in my application which is being encountered on the live system.  That does bear investigation.

'''
I, [2016-11-10T11:20:59.760155 #25024]  INFO -- : Started POST "/commitments" for 62.254.17.242 at 2016-11-10 11:20:59 +0000
I, [2016-11-10T11:20:59.763571 #25024]  INFO -- : Processing by CommitmentsController#create as JS
I, [2016-11-10T11:20:59.763679 #25024]  INFO -- :   Parameters: {"utf8"=>"âœ“", "commitment"=>{"element_name"=>"", "element_id"=>"", "event_id"=>"477568"}}
I, [2016-11-10T11:20:59.776383 #25024]  INFO -- : Completed 500 Internal Server Error in 13ms
F, [2016-11-10T11:20:59.781093 #25024] FATAL -- :
NoMethodError (undefined method `owned' for nil:NilClass):
  app/models/user.rb:284:in `needs_permission_for?'
  app/controllers/commitments_controller.rb:68:in `create'
'''


Sounds like someone is trying to create a commitment without success.

Calling needs_permission_for? with a nil element.  How?  They seem to have tried to create a commitment, without specifying an element for it.  That's odd.  They are however providing an event id.

Hang on - I'm looking at concerns - this is commitments.  They're probably doing something amusing with the dialogue.  Yes, just pressing return on a blank field produces this problem.  I'm assuming there's an element there when checking the permissions, but the original design of the method leaves the checking for the save code.  Just put an extra check in.  Will need to go back to the master branch and create a hotfix.

Done that - good.

Back to cron jobs.  When are the current cron jobs?

System backup is at 06:00
iSAMS data import is at 04:00.  Takes about 9 mins currently.
Daily report - which generates e-mails about pending approvals - is at 06:00

The most logical thing would be to run the backup before all the updates.  I don't know whether Greg would be willing to move it though - one can but ask.  However, it would certainly make sense to do the iSAMS update before the clash checking, which should in turn be before the run which reports proposed absences.  Should all fit in the available time though, but not after the backup at 06:00.

Ah, no.  The time of the actual system backup is not crucial.  What matters is when the database is dumped.  I dump it to a file, which is then included in the system backup.  This happens at 02:30 each day.  Assuming we don't suffer a catastrophic disk failure, this is enough to recover from a data update error.  I keep two days worth on disk anyway.  The time for the d/b dump is negligible.

The crucial thing is to dump the database after the users have spent the day entering stuff, but before I start the automated processing.  That way if something horrendous goes wrong with the automated update, we can still recover to the position of close-of-play the previous day, thus not losing anyone's hard work.

Sequence should be:

* Dump database to file
* iSAMS data import (includes cover checking + e-mails)
* Absentee/clash checking (includes e-mails for those requesting immediate)
* Daily/weekly absentee/clash e-mails
* Daily pending requests e-mails

and then the system backup can happen when it wants to.  Ideally we should have finished all the above before it needs to happen.  How about:

02:15 Dump database (every day)
02:30 iSAMS data import (every day)
03:00 Absentee/clash checking (Sun, Mon, Tue, Wed, Thu, Fri)
05:30 Weekly absentee report (Sun only)
05:30 Daily absentee report (Mon, Tue, Wed, Thu, Fri)
05:45 Daily pending request e-mail

There is no point in doing the clash checking in the small hours of Saturday because it will check only Saturday.
That gives us 2H30 for the clash check run.  On my development PC it takes just over an hour (i7, SSD, but development mode so vast logs).  On my staging server it takes two hours (mobile i5, iSCSI to HDD, production mode).  We'll just have to see how long it takes on the live server.
