Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2015-08-24T08:39:37+01:00

====== Monday 24 Aug 2015 ======

I spent the latter part of yesterday writing a brand new bit of code for calculating set membership.  It seems to work well, although I am slightly puzzled by some of the database queries it produces.  I think I need to add some debug code to ensure I understand exactly what it is doing - and be sure it can't be optimised further.

I've also thought of what I believe is an efficient way of handling exclusions.  I'll work on that next.  I've yet to figure out a way of doing as_at processing efficiently, so I think they're going to go by the board.  The method is to assemble my group list, with dates, first, then go through them and if any of them has an exclusion you look for the same group in the inclusions and subtract the dates.  Need also to cope with exclusions of an individual, but the only individual exclusion we're interested in is of the element with which we started.  It is possible to set up a mutual exclusion situation where two groups exclude each other, but in that case the result will be undefined (although the code will continue to run).

To avoid extra d/b queries, I might add a "has_exclusions" flag to the group record.  This would be set/cleared as exclusions are created or deleted, and means I don't have to do an extra d/b query just to find out whether they exist (which they usually won't.)  Or it might be possible to preload membership records with each group - how much would that cost?

So, todo:

[*] Add debug code to existing stuff to see exactly what is happening
[*] Encapsulate new processing in a collection object
[*] Add exclusion processing
[ ] Having got my list, use AREL to generate a single d/b query to retrieve all corresponding commitments.
[ ] And try that as a replacement for commitments_on.

Carry on testing with Angus Alder, who is 10036.  If do a run starting at 2015-09-01 and ending at nil I get 46 positives for Angus.  According to Benchmark, it takes 0.09248 seconds on my PC, so 92ms.  Not bad.

I am slightly puzzled however by calls like this:


'''
Membership Load (0.2ms)  SELECT `memberships`.* FROM `memberships`  WHERE `memberships`.`element_id` = 18303 AND `memberships`.`inverse` = 0 AND (ends_on IS NULL OR ends_on >= '2015-09-03')
Group Load (0.2ms)  SELECT `groups`.* FROM `groups`  WHERE `groups`.`id` IN (12517, 12620)
Element Load (0.2ms)  SELECT `elements`.* FROM `elements`  WHERE `elements`.`entity_type` = 'Group' AND `elements`.`entity_id` IN (12517, 12620)
'''


Why do I keep getting two groups loaded at the same time?

Element 18303 is "S5 A El".  Ah - it has two memberships for "Electronics pupils" (group_id 12517) and "5th year Electronics pupils" (group_id 12620).  Then I load both those groups' elements, and move on.  Can I preload the parent memberships when I load a group?  It seems a tiny bit slower, but not enough to be significant.  Forget it for now.

OK - on to encapsulation.  I really need to encapsulate all this clever processing in an object which knows how to accumulate the results, and then do the next bit of processing.

Had a thought - when I get around to to the final step of the processing, I will need the element_id for each group, but what I'm currently storing is the membership.  At the point where I'm storing it I believe I have the group (and indeed, element) in memory.  If I find they're being fetched again later then I'll need to cache the element id explicitly.

OK - the processing is now more encapsulated, what about exclusions?

Need a fresh copy of the live system which has my non-tutors group in it.  Got it.  Currently it shows Martin Poon (10414) as a member of the non-tutors group which it shouldn't because he is a tutor.  I need to fix the code so that he appears not to be in the non-tutors group, but I still appear there.

Just added code to detect exclusions using the existing d/b structure.  It appears that the groups are already in memory, so I just get one d/b hit for each of the groups checking its memberships.  This may or may not be a problem.  As a future optimisation I can get rid of this by adding a "has_exclusions" flag to the group record, and maintaining it as membership records are created or deleted.  Or can I preload the memberships?  Doesn't seem to help.  Leave it for now and see whether performance is acceptable.

Tried to improve the following code by pre-loading the element whilst grabbing the exclusions.  It seems to lead to much more complicated SQL, but is it any slower?  Test.  Without the preload we seem to be looking at 0.2ms each.  With the preload they seem to be consistently 0.1ms each, which is weird.  I'll leave it in for now.

Why is Angus Alder not appearing as a member of the Mandarin Students group?  He was until 30th August 2015, but doesn't seem to be now.  Ah - could it be part of my processing is ignoring the group when it appears a second time?  Yes, I think it is.  The problem is I'm find the group twice, via two different routes and I'm ignoring it the second time.

I need to fix that, plus I need to modify my set management to cope with two different entries for the same group.  If two are directly adjacent they should be merged, but I also need to cope with there potentially being just more than one of them.  At present my hash will keep track of only one.

Two adjacent occurrences will actually be quite common for something like "Mandarin pupils".  Should we combine them?  I can think of arguments either way.  I think I'll leave them separate for now, but we'll need to extend the processing a bit to cope with multiple entries.

I think that bit is now working.  I've tried a group exclusion and an individual exclusion.

Now we move on and try to use Arel to get the corresponding events.

Just noticed that my existing code already builds its own SQL, because I want to do it dynamically and ActiveRecord didn't seem to provide quite enough.  I could build my OR conditions that way too.

There are a number of parameters to commitments_on which I cope with at present, and I could really do to carry on coping with them.

startdate			First date for commitments to return
enddate				Last date for commitments.  Nil means we want just the one day.
eventcategory		Single event category, or array of event categories to restrict the query to.
eventsource			Likewise for event sources
resource				Single resource or array of resources to query for
owned_by			Single user or array of users to restrict to events owned by
include_nonexistent	Whether or not to include non_existent events

Now for this modified version, it only really makes sense to cater for one resource, but I need to add the ability to pass in a set of MWDs.

So my query needs to be:

Commitments.where( eventcategories are right AND
                                    eventsources are right AND
                                    owned_by is right AND
                                    possibly remove non-existent AND
                                    (matches resource and startdate and end date OR
                           for each MWD group
                                    (matches any resource and startdate and end date) OR
                           end for
)

It would be a help if each group could provide its start and end times - or even the collection could have a to_sql method to generate the necessary snippet of SQL.  Try that.

Actually, I'm not quite creating raw SQL - I'm letting Rails interpolate values into it.

Got a version working, hand-crafting my own SQL.  It's more than a trifle messy, and I've realised I'm using two different conventions which are getting confused.  For direct commitments I'm using a convention that an end_date of nil means to use the same date as the start, whilst for the group commitments it means go on for ever.  Need to make these consistent.  Also, found a better way of formatting date strings - to_s(:db) will do it.

Some tidying need tomorrow, but a very effective day's work.
                             
