#!/bin/bash
#
#  This is a modified version if the importisdata script designed
#  to work around bugs in the iSAMS API.  Instead of fetching
#  the data all in one go, we do it in stages and then combine them.
#
. /etc/profile
#
#  The next file contains confidential authentication information,
#  specifically the apikey for the API and the password for direct
#  d/b access.  In a separate file so we can commit this file
#  to version control.
#
. ~/etc/isauth
#
#  Are we on development or live?  Where are our directories etc?
#
. ~/etc/whichsystem
#
#  And make sure we're using the right ruby.
#
. ~/.rvm/environments/scheduler
#
#
#  Now some checks to make sure that at least the part of the
#  environment which we need has been set.
#
if [ "a$SCHEDULER_DIR" == "a" ]; then
  echo "SCHEDULER_DIR environment variable needs to be set."
  exit 1
fi
if [ ! -d $SCHEDULER_DIR/import/isams ]; then
  echo "$SCHEDULER_DIR/import/isams does not seem to be a directory."
  exit 2
fi
if [ "a$IMPORT_OPTS" == "a" ]; then
  echo "IMPORT_OPTS environment variable needs to be set."
  exit 9
fi

cd $SCHEDULER_DIR/import/isams
rm -f Incoming/*

#
#  Are we making use of data from the iSAMS API - either fetching it
#  now or an old one which we have to hand?
#
#  Processing is done in a significantly different order here.  We might
#  have some files pre-existing, and fetch the rest.
#
if [ "$USE_ISAMS_API" = true ]; then
  if [ "a$ISAMS_API_URL" == "a" ]; then
    echo "ISAMS_API_URL environment variable needs to be set."
    exit 3
  fi
  if [ "a$APIKEYS" == "a" ]; then
    echo "APIKEYS environment variable needs to be set."
    exit 4
  fi
  for key in $APIKEYS; do
    #
    #  Don't use the key itself as a filename - insecure.  Generate an
    #  MD5SUM from the number and use that.
    #
    filename=`$SCHEDULER_DIR/utils/domd5 $key`
    if [ -f PreFetched/$filename.xml ]; then
      echo "Using pre-fetched $filename.xml"
      cp PreFetched/$filename.xml Incoming
    else
      #
      #  There are lots of issues in iSAMS's batch API which they seem
      #  to be incapable of fixing.  We are trying to work around them.
      #
      #  We make up to two attempts for each file (with a delay in
      #  between if we need the second attempt), and also do a delay
      #  between queries.
      #
      time curl --silent $ISAMS_API_URL?apikey=$key --output Incoming/$filename.xml
      if [ $? -ne 0 ]; then
        echo "Failed to fetch iSAMS API data 1."
        exit 5
      fi
      #
      #  Process the received file as if to merge it, just to check
      #  it is potentially mergeable.  If not then we will try again
      #  to fetch it.
      #
      $SCHEDULER_DIR/lib/xmlcat/xmlcat.rb --error_element "Message" --nest_at 'iSAMS' Incoming/$filename.xml >/dev/null
      if [ $? -ne 0 ]; then
        #
        #  iSAMS has failed to process the first request.  Wait 5 seconds
        #  and try again.  We make only two attempts for each file.
        #
        echo "iSAMS failed to generate $filename.xml - waiting 5 seconds."
        sleep 5
        echo "Trying again."
        time curl --silent $ISAMS_API_URL?apikey=$key --output Incoming/$filename.xml
        if [ $? -ne 0 ]; then
          echo "Failed to fetch iSAMS API data 2."
          exit 8
        fi
        #
        #  No real point in testing it again now.  If iSAMS has failed again
        #  then it will be detected at the main merge step.
        #
      fi
      #
      #  A delay in the hope it will help iSAMS to cope.
      #
      sleep 10
    fi
  done
  #
  #  And now combine all our files to make the data.xml file which
  #  we wanted in the first place.
  #
  $SCHEDULER_DIR/lib/xmlcat/xmlcat.rb --error_element "Message" --nest_at 'iSAMS' Incoming/*.xml >Incoming/data.xml
  if [ $? -eq 0 ]; then
    #
    #  Keep a copy of this successfully merged file in case of failures
    #  on future occasions.
    #
    cp Incoming/data.xml LastGood
  else
    echo "Failed to merge iSAMS XML files."
    #
    #  Might be able to revcover if we have an old data file.
    #
    if [ -f LastGood/data.xml ]; then
      cp LastGood/data.xml Incoming
      mail monitors -s "Scheduler import using old saved data.xml" << EOF
Merging of XML files from iSAMS has failed.  Using an old copy.
EOF
    else
      echo "No old data file to use."
      exit 7
    fi
  fi
else
  echo "Not using iSAMS API data."
fi

#
#  And are we using additional data retrieved directly from the iSAMS
#  database - again either doing it now or having done it earlier?
#
if [ "$USE_ISAMS_DB" = true ]; then
  if [ -f PreFetched/TblActivityManagerEvent.csv ]; then
    echo "Using pre-fetched csv files."
    cp PreFetched/*.csv Incoming
  else
    echo "Doing direct d/b access."
    time $SCHEDULER_DIR/utils/fetchisdata/extractor.rb --target Incoming --extract
    if [ $? -ne 0 ]; then
      echo "Failed to fetch data from iSAMS database."
      exit 6
    fi
  fi
else
  echo "Not using iSAMS table data."
fi

#
#  We now appear to have a set of data files.  Move them to Current
#  and then archive them.
#
#  Note that we are keeping *all* our XML files - the ones from iSAMS
#  and the merged one.  This is to aid in problem diagnosis in the future.
#
rm -f Current/*
mv Incoming/* Current
TARGET_DIR="Archive/`date +%Y/%m/%d`"
mkdir -p $TARGET_DIR
cp Current/* $TARGET_DIR
if [ "$USE_ISAMS_API" = true ]; then
  bzip2 -f $TARGET_DIR/*.xml
fi
if [ "$USE_ISAMS_DB" = true ]; then
  bzip2 -f $TARGET_DIR/*.csv
fi

#
#  And now invoke the import utility to bring the new data into Scheduler.
#
$SCHEDULER_DIR/lib/import/misimport.rb "${IMPORT_OPTS[@]}" | tee import.log
cp import.log $TARGET_DIR
bzip2 -f $TARGET_DIR/import.log

